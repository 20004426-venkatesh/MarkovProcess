# Markov Process


# Aim : 

To calculate n-th step  probability distribution  matrix of the three state Markov chain whose transition probability matrix 
![image](https://user-images.githubusercontent.com/104613195/170176323-3b55c6cd-912c-4c89-bd9e-d3a60660ecd0.png) with initial probability matrix (0.3 0.2 0.5).


# Software required :  

Python

# Theory:




# Procedure :

![image](https://user-images.githubusercontent.com/104613195/170175685-c6187523-f268-4a3b-b03d-8bbe62647a57.png)



# Program




# Results and Output : 

